{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "import argparse\n",
    "import joblib\n",
    "import sys\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(filename='model_training.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.INFO)\n",
    "logging.getLogger('').addHandler(console)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"Load dataset from file.\"\"\"\n",
    "    try:\n",
    "        logging.info(\"Loading dataset from %s\", file_path)\n",
    "        return pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error loading dataset: %s\", e)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    \"\"\"Split dataset into train, validation, and test sets.\"\"\"\n",
    "    try:\n",
    "        logging.info(\"Splitting dataset.\")\n",
    "        X = df.drop(columns=[\"concrete_compressive_strength\"])\n",
    "        y = df[\"concrete_compressive_strength\"]\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1/3, random_state=42)\n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error splitting dataset: %s\", e)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(models, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Train and evaluate multiple models.\"\"\"\n",
    "    logging.info(\"Training and evaluating models.\")\n",
    "    model_results = {}\n",
    "    for name, model in models.items():\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_val)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            mse = mean_squared_error(y_val, y_pred)\n",
    "            rmse = mse ** 0.5\n",
    "            r2 = r2_score(y_val, y_pred)\n",
    "            latency = end_time - start_time\n",
    "\n",
    "            model_results[name] = {\"MSE\": mse, \"RMSE\": rmse, \"R² Score\": r2, \"Latency (s)\": latency}\n",
    "            logging.info(f\"{name} - MSE: {mse}, RMSE: {rmse}, R² Score: {r2}, Latency: {latency}\")\n",
    "        except Exception as e:\n",
    "            logging.error(\"Error training %s: %s\", name, e)\n",
    "    return pd.DataFrame(model_results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(X_train, y_train):\n",
    "    \"\"\"Perform hyperparameter tuning for Random Forest and save best model.\"\"\"\n",
    "    try:\n",
    "        logging.info(\"Starting hyperparameter tuning for Random Forest.\")\n",
    "        param_grid = {\"n_estimators\": [50, 100, 150], \"max_depth\": [5, 10, 15]}\n",
    "        rf_model = RandomForestRegressor(random_state=42)\n",
    "        grid_search = GridSearchCV(rf_model, param_grid, cv=3, scoring=\"r2\", n_jobs=-1, verbose=1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        joblib.dump(best_model, \"best_rf_model.pkl\")\n",
    "        logging.info(f\"Best RF Params: {grid_search.best_params_}, Best RF R² Score: {grid_search.best_score_}\")\n",
    "        return grid_search.best_params_, grid_search.best_score_\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error in hyperparameter tuning: %s\", e)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_jupyter_notebook():\n",
    "    \"\"\"Detect if the script is running in a Jupyter Notebook.\"\"\"\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        return get_ipython() is not None\n",
    "    except ImportError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running in Jupyter Notebook. Using default dataset.\n",
      "Running in Jupyter Notebook. Using default dataset.\n",
      "Running in Jupyter Notebook. Using default dataset.\n",
      "Loading dataset from concrete_data.csv\n",
      "Loading dataset from concrete_data.csv\n",
      "Loading dataset from concrete_data.csv\n",
      "Splitting dataset.\n",
      "Splitting dataset.\n",
      "Splitting dataset.\n",
      "Training and evaluating models.\n",
      "Training and evaluating models.\n",
      "Training and evaluating models.\n",
      "Linear Regression - MSE: 113.44365763931016, RMSE: 10.650993270080972, R² Score: 0.6006252770706919, Latency: 0.005258798599243164\n",
      "Linear Regression - MSE: 113.44365763931016, RMSE: 10.650993270080972, R² Score: 0.6006252770706919, Latency: 0.005258798599243164\n",
      "Linear Regression - MSE: 113.44365763931016, RMSE: 10.650993270080972, R² Score: 0.6006252770706919, Latency: 0.005258798599243164\n",
      "Decision Tree - MSE: 48.65592669902914, RMSE: 6.975380039756195, R² Score: 0.8287083857426686, Latency: 0.04659008979797363\n",
      "Decision Tree - MSE: 48.65592669902914, RMSE: 6.975380039756195, R² Score: 0.8287083857426686, Latency: 0.04659008979797363\n",
      "Decision Tree - MSE: 48.65592669902914, RMSE: 6.975380039756195, R² Score: 0.8287083857426686, Latency: 0.04659008979797363\n",
      "Random Forest - MSE: 26.613475303985123, RMSE: 5.158824992571964, R² Score: 0.9063081220502538, Latency: 1.7633042335510254\n",
      "Random Forest - MSE: 26.613475303985123, RMSE: 5.158824992571964, R² Score: 0.9063081220502538, Latency: 1.7633042335510254\n",
      "Random Forest - MSE: 26.613475303985123, RMSE: 5.158824992571964, R² Score: 0.9063081220502538, Latency: 1.7633042335510254\n",
      "XGBoost - MSE: 19.705483580885385, RMSE: 4.439085894740649, R² Score: 0.9306274832011667, Latency: 0.10118341445922852\n",
      "XGBoost - MSE: 19.705483580885385, RMSE: 4.439085894740649, R² Score: 0.9306274832011667, Latency: 0.10118341445922852\n",
      "XGBoost - MSE: 19.705483580885385, RMSE: 4.439085894740649, R² Score: 0.9306274832011667, Latency: 0.10118341445922852\n",
      "Starting hyperparameter tuning for Random Forest.\n",
      "Starting hyperparameter tuning for Random Forest.\n",
      "Starting hyperparameter tuning for Random Forest.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          MSE       RMSE  R² Score  Latency (s)\n",
      "Linear Regression  113.443658  10.650993  0.600625     0.005259\n",
      "Decision Tree       48.655927   6.975380  0.828708     0.046590\n",
      "Random Forest       26.613475   5.158825  0.906308     1.763304\n",
      "XGBoost             19.705484   4.439086  0.930627     0.101183\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best RF Params: {'max_depth': 15, 'n_estimators': 150}, Best RF R² Score: 0.8847256340402937\n",
      "Best RF Params: {'max_depth': 15, 'n_estimators': 150}, Best RF R² Score: 0.8847256340402937\n",
      "Best RF Params: {'max_depth': 15, 'n_estimators': 150}, Best RF R² Score: 0.8847256340402937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Params: {'max_depth': 15, 'n_estimators': 150}\n",
      "Best RF R² Score: 0.8847256340402937\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if is_jupyter_notebook():\n",
    "        logging.info(\"Running in Jupyter Notebook. Using default dataset.\")\n",
    "        data_path = \"concrete_data.csv\"\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser(description=\"Train ML models on concrete dataset.\")\n",
    "        parser.add_argument(\"--data\", type=str, default=\"cleaned_dataset.csv\", help=\"Path to dataset\")\n",
    "        args = parser.parse_args()\n",
    "        data_path = args.data\n",
    "    \n",
    "    df = load_data(data_path)\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(df)\n",
    "    \n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "        \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        \"XGBoost\": XGBRegressor(objective=\"reg:squarederror\", n_estimators=50, random_state=42)\n",
    "    }\n",
    "    \n",
    "    results_df = train_and_evaluate(models, X_train, y_train, X_val, y_val)\n",
    "    print(results_df)\n",
    "    \n",
    "    best_params, best_score = hyperparameter_tuning(X_train, y_train)\n",
    "    print(\"Best RF Params:\", best_params)\n",
    "    print(\"Best RF R² Score:\", best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
